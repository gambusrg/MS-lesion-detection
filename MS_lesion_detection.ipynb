{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-56B4VtVmgxQ"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nnunetv2"
      ],
      "metadata": {
        "id": "xpwZbx2WWdKl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "050a1e2c-5ea3-46bd-d447-e0a538c3de21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ht3nKMs1y0mw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        },
        "outputId": "470b15f3-32c7-475a-c434-8e0d4cfb078d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed SimpleITK-2.3.1 acvl-utils-0.2 argparse-1.4.0 batchgenerators-0.25 connected-components-3d-3.14.1 dicom2nifti-2.4.10 dynamic-network-architectures-0.3.1 imagecodecs-2024.1.1 linecache2-1.0.0 nnunetv2-2.4.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 pydicom-2.4.4 python-gdcm-3.0.24 traceback2-1.4.0 unittest2-1.1.0 yacs-0.1.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse"
                ]
              },
              "id": "9b7af3a7235c4127aa3853e4505a03e2"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Import basic packages for later use\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "from collections import OrderedDict, defaultdict\n",
        "import re\n",
        "\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import nibabel as nib\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import nnunetv2\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Pw6lHfZVxXZq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc5fae6e-866c-4f94-e5a4-000f30fc4407"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "UNRAR 6.11 beta 1 freeware      Copyright (c) 1993-2022 Alexander Roshal\n",
            "\n",
            "Cannot open /content/drive/MyDrive/nnUNET_SELs.rar\n",
            "No such file or directory\n",
            "No files to extract\n"
          ]
        }
      ],
      "source": [
        "!unrar x \"/content/drive/MyDrive/nnUNET_SELs.rar\" \"/content/\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tree Folder Structure"
      ],
      "metadata": {
        "id": "sLzu1YFMxvSn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLJ0YPaW1PhD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "from collections import defaultdict\n",
        "\n",
        "def setup_nnunet_dir(base_directory, dataset_name):\n",
        "    \"\"\"\n",
        "    Sets up nnUNet directories and organizes files based on their names.\n",
        "\n",
        "    Args:\n",
        "    - base_directory (str): The base directory where nnUNet directories will be created.\n",
        "    - dataset_name (str): The name of the dataset, e.g., \"Dataset101\".\n",
        "    \"\"\"\n",
        "    # Create nnUNet directories\n",
        "    nnunet_directory = os.path.join(base_directory, \"nnUNet\")\n",
        "    os.makedirs(nnunet_directory, exist_ok=True)\n",
        "\n",
        "    # Create nnUNet_preprocessed and nnUNet_results directories inside nnUNet\n",
        "    for subdirectory in [\"nnUNet_preprocessed\", \"nnUNet_results\"]:\n",
        "        os.makedirs(os.path.join(nnunet_directory, subdirectory), exist_ok=True)\n",
        "\n",
        "    # Create directories nnUNet_raw/Dataset101_SEL/imagesTr and nnUNet_raw/Dataset101/labelsTr\n",
        "    for subdirectory in [\"imagesTr\", \"imagesTs\", \"labelsTr\"]:\n",
        "        os.makedirs(os.path.join(nnunet_directory, \"nnUNet_raw\", dataset_name, subdirectory), exist_ok=True)\n",
        "\n",
        "    # Directory where the images are located\n",
        "    images_directory = os.path.join(base_directory, \"nnUNet\", \"nnUNet_raw\", dataset_name)\n",
        "\n",
        "    # Dictionary to store files by group (based on the first number between \"_XXX_\")\n",
        "    files_by_group = defaultdict(list)\n",
        "\n",
        "    # Iterate over the files in the directory\n",
        "    for file in os.listdir(base_directory):\n",
        "        if file.endswith(\".nii.gz\"):\n",
        "            # Check if the file contains the word \"SEL\" or \"lesion_mask\"\n",
        "            if \"SEL\" in file:\n",
        "                os.remove(os.path.join(base_directory, file))\n",
        "            elif \"lesion_mask\" in file:\n",
        "                shutil.move(os.path.join(base_directory, file), os.path.join(nnunet_directory, \"nnUNet_raw\", dataset_name, \"labelsTr\", file))\n",
        "            else:\n",
        "                shutil.move(os.path.join(base_directory, file), os.path.join(nnunet_directory, \"nnUNet_raw\", dataset_name, \"imagesTr\", file))\n",
        "\n",
        "# Example usage:\n",
        "base_directory = \"/content/nnUNet\"\n",
        "dataset_name = input(\"Enter the name of the dataset, e.g., 'Dataset101': \")\n",
        "setup_nnunet_dir(base_directory, dataset_name)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## imagesTr structure"
      ],
      "metadata": {
        "id": "qobWYmZM7dc_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "def rename_files(directory):\n",
        "    # Regular expression to find a three-digit number between underscores in the filename\n",
        "    pattern = re.compile(r\"_(\\d{3})_\")\n",
        "\n",
        "    # Dictionary to keep track of the final number for each unique three-digit number\n",
        "    final_numbers = {}\n",
        "\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith(\".nii.gz\"):\n",
        "            # Match with the pattern\n",
        "            match = pattern.search(filename)\n",
        "\n",
        "            if match:\n",
        "                # Extract the three-digit number\n",
        "                number = match.group(1)\n",
        "\n",
        "                # Increment the final number for this three-digit number\n",
        "                if number not in final_numbers:\n",
        "                    final_numbers[number] = 0\n",
        "                else:\n",
        "                    final_numbers[number] += 1\n",
        "\n",
        "                # New filename\n",
        "                new_filename = f\"{number}_{final_numbers[number]:04d}.nii.gz\"\n",
        "\n",
        "                os.rename(os.path.join(directory, filename), os.path.join(directory, new_filename))\n",
        "\n",
        "# Example usage:\n",
        "directory = \"/content/nnUNet/nnUNet_raw/Dataset101/imagesTr\"\n",
        "rename_files(directory)"
      ],
      "metadata": {
        "id": "d2nAG9a43yF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_basal(directory):\n",
        "\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith(\".nii.gz\") and not (filename.endswith(\"0.nii.gz\") or filename.endswith(\"1.nii.gz\")):\n",
        "            os.remove(os.path.join(directory, filename))\n",
        "\n",
        "# Example usage:\n",
        "directory = \"/content/nnUNet/nnUNet_raw/Dataset101/imagesTr\"  # Adjust the directory path as needed\n",
        "get_basal(directory)"
      ],
      "metadata": {
        "id": "oTSUCSIa8KiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## labelTr structure"
      ],
      "metadata": {
        "id": "oJYYPRA081RW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rename_labelTr(directory):\n",
        "\n",
        "    # Regular expression to find a three-digit number in the filename\n",
        "    pattern = re.compile(r\"(\\d{3})\")\n",
        "\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith(\".nii.gz\"):\n",
        "            # Match with the pattern\n",
        "            match = pattern.search(filename)\n",
        "            if match:\n",
        "                # New filename\n",
        "                new_filename = f\"{match.group(1)}.nii.gz\"\n",
        "                os.rename(os.path.join(directory, filename), os.path.join(directory, new_filename))\n",
        "\n",
        "# Example usage:\n",
        "directory = \"/content/nnUNet/nnUNet_raw/Dataset101/labelsTr\"  # Adjust the directory path as needed\n",
        "rename_labelTr(directory)"
      ],
      "metadata": {
        "id": "YM81YOAn87id"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Test Split"
      ],
      "metadata": {
        "id": "kYso-jVl9vhO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKLXdKzTxnRP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import re\n",
        "\n",
        "def move_to_imagesTs(imagesTr_directory):\n",
        "\n",
        "    # Create directory for imagesTs\n",
        "    imagesTs_directory = os.path.join(imagesTr_directory, \"..\", \"imagesTs\")\n",
        "    os.makedirs(imagesTs_directory, exist_ok=True)\n",
        "\n",
        "    # Get all filenames in the imagesTr directory\n",
        "    filenames = [f for f in os.listdir(imagesTr_directory) if f.endswith(\".nii.gz\")]\n",
        "\n",
        "    # Extract identifiers (XXX) from filenames\n",
        "    pattern = re.compile(r\"(\\d{3})_000[01]\\.nii.gz\")\n",
        "    identifiers = set(match.group(1) for filename in filenames if (match := pattern.match(filename)))\n",
        "\n",
        "    # Calculate the number of identifiers to move to imagesTs (20%)\n",
        "    num_identifiers_to_move = int(len(identifiers) * 0.2)\n",
        "    identifiers_list = list(identifiers)\n",
        "\n",
        "    # Randomly select identifiers to move\n",
        "    identifiers_to_move = random.sample(identifiers_list, num_identifiers_to_move)\n",
        "\n",
        "    # Move the selected identifiers' files to imagesTs\n",
        "    for identifier in identifiers_to_move:\n",
        "        files_with_identifier = [f for f in filenames if f.startswith(f\"{identifier}_\")]\n",
        "        files_to_move = random.sample(files_with_identifier, min(2, len(files_with_identifier)))  # Ensure we have at most 2 files per identifier\n",
        "        for filename in files_to_move:\n",
        "            shutil.move(os.path.join(imagesTr_directory, filename), os.path.join(imagesTs_directory, filename))\n",
        "\n",
        "    return list(identifiers_to_move)\n",
        "\n",
        "# Example usage:\n",
        "imagesTr_directory = \"/content/nnUNet/nnUNet_raw/Dataset101/imagesTr\"\n",
        "identifiers_imagesTs = move_to_imagesTs(imagesTr_directory)\n",
        "print(\"Identifiers extracted from filenames:\", identifiers_imagesTs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def move_to_labelsTest(dataset_directory, identifiers):\n",
        "    \"\"\"\n",
        "    Moves files from labelsTr to labelsTest if their identifier matches any identifier in the list.\n",
        "\n",
        "    Args:\n",
        "    - dataset_directory (str): The directory path containing the dataset folders (labelsTr, labelsTest, etc.).\n",
        "    - identifiers (list): List of identifiers to check against.\n",
        "    \"\"\"\n",
        "    # Create directory for labelsTest\n",
        "    labelsTest_directory = os.path.join(dataset_directory, \"labelsTest\")\n",
        "    os.makedirs(labelsTest_directory, exist_ok=True)\n",
        "\n",
        "    # Iterate over identifiers\n",
        "    for identifier in identifiers:\n",
        "        # Check if any file in labelsTr contains the identifier\n",
        "        for filename in os.listdir(os.path.join(dataset_directory, \"labelsTr\")):\n",
        "            if identifier in filename:\n",
        "                # Move file to labelsTest\n",
        "                shutil.move(os.path.join(dataset_directory, \"labelsTr\", filename), os.path.join(labelsTest_directory, filename))\n",
        "\n",
        "# Example usage:\n",
        "dataset_directory = \"/content/nnUNet/nnUNet_raw/Dataset101\"\n",
        "identifiers = identifiers_imagesTs\n",
        "move_to_labelsTest(dataset_directory, identifiers)"
      ],
      "metadata": {
        "id": "FPREulmiBv77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDQmW0dP5OJn"
      },
      "outputs": [],
      "source": [
        "### NO ES FA SERVIR\n",
        "\n",
        "# Directorio donde se encuentran las imágenes\n",
        "directorio = \"/content/nnUNet/nnUNet_raw/Dataset101/labelsTr\"\n",
        "directorio_imagenes = os.listdir(directorio)\n",
        "regex = r'_(\\d+)_'\n",
        "\n",
        "def ordenar_por_numeros(nombre_archivo):\n",
        "    # Separar el nombre del archivo en partes usando \"_\"\n",
        "    partes = nombre_archivo.split('_')\n",
        "    # Extraer el número entre los guiones bajos\n",
        "    numero = int(partes[1])\n",
        "    return numero\n",
        "\n",
        "directorio_imagenes = sorted(directorio_imagenes, key=ordenar_por_numeros)\n",
        "\n",
        "for i in range(len(directorio_imagenes)):\n",
        "\n",
        "    if i % 3 == 0:\n",
        "\n",
        "        id_1 = re.findall(regex, directorio_imagenes[i])[0]\n",
        "        id_2 = re.findall(regex, directorio_imagenes[i + 1])[0]\n",
        "        id_3 = re.findall(regex, directorio_imagenes[i + 2])[0]\n",
        "\n",
        "\n",
        "        if id_1 == id_2 == id_3:\n",
        "\n",
        "\n",
        "            ruta_imagen1 = os.path.join(directorio, \"rMSVIS_\" + id_1 + \"_T1_definite_SELs_mask.nii.gz\")\n",
        "            ruta_imagen2 = os.path.join(directorio, \"rMSVIS_\" + id_1 + \"_T1_non_SELs_mask.nii.gz\")\n",
        "            ruta_imagen3 = os.path.join(directorio, \"rMSVIS_\" + id_1 + \"_T1_possible_SELs_mask.nii.gz\")\n",
        "\n",
        "            # Cargar las imágenes MRI\n",
        "            imagen1 = nib.load(ruta_imagen1)\n",
        "            imagen2 = nib.load(ruta_imagen2)\n",
        "            imagen3 = nib.load(ruta_imagen3)\n",
        "\n",
        "            # Obtener los datos de las imágenes en un array numpy de 3 dimensiones\n",
        "            datos_imagen1 = imagen1.get_fdata()\n",
        "            datos_imagen2 = imagen2.get_fdata()\n",
        "            datos_imagen3 = imagen3.get_fdata()\n",
        "\n",
        "            # Aplicar umbralización para convertir los datos a valores binarios (0 o 1)\n",
        "            datos_imagen1_binario = (datos_imagen1 > 0).astype(np.float32)\n",
        "            datos_imagen2_binario = (datos_imagen2 > 0).astype(np.float32)\n",
        "            datos_imagen3_binario = (datos_imagen3 > 0).astype(np.float32)\n",
        "\n",
        "            # Aplicar el mapeo a los datos de la máscara SEL\n",
        "            datos_imagen1_binario_mapped = np.where(datos_imagen1_binario == 1, 2, 0)\n",
        "            datos_imagen3_binario_mapped = np.where(datos_imagen3_binario == 1, 2, 0)\n",
        "\n",
        "            # Combinar las dos imágenes en una sola\n",
        "            datos_imagen_combinada = datos_imagen1_binario_mapped + datos_imagen3_binario_mapped + datos_imagen2_binario\n",
        "            datos_imagen_combinada[datos_imagen_combinada == 3] = 2\n",
        "            datos_imagen_combinada[np.isnan(datos_imagen_combinada)] = 0\n",
        "\n",
        "            # Crear una instancia de Nifti1Image con los datos de la máscara combinada\n",
        "            output_nii_combinada = nib.Nifti1Image(datos_imagen_combinada, affine=imagen1.affine)\n",
        "\n",
        "            # Imprimir los labels únicos en la máscara combinada\n",
        "            unique_labels_combinada = np.unique(output_nii_combinada.get_fdata())\n",
        "            print(\"Unique labels in the combined image:\", unique_labels_combinada, id_1 )\n",
        "\n",
        "            # Guardar la nueva imagen en formato NIfTI (.nii.gz)\n",
        "            nombre_archivo_combinado = id_1 + \".nii.gz\"\n",
        "            ruta_completa_archivo_combinado = os.path.join(directorio, nombre_archivo_combinado)\n",
        "            nib.save(output_nii_combinada, ruta_completa_archivo_combinado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLPFA6I72Vbb"
      },
      "source": [
        "## Set Env var"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1kCEjiykI8v"
      },
      "outputs": [],
      "source": [
        "output_folder = '/content/nnUNet/nnUNet_raw/Dataset101'\n",
        "channel_names = {0: 'BaseLineFL', 1: 'BaseLineT1'}\n",
        "labels = {'background':0, 'lesion': 1}\n",
        "file_ending = '.nii.gz'\n",
        "num_training_cases = 106\n",
        "dataset_name = 'sels'\n",
        "description = 'sels segmentation'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3Jaz3Dik4hP"
      },
      "outputs": [],
      "source": [
        "from nnunetv2.dataset_conversion.generate_dataset_json import generate_dataset_json\n",
        "generate_dataset_json(output_folder=output_folder,channel_names=channel_names, labels=labels,\n",
        "                      file_ending=file_ending,\n",
        "                      num_training_cases=num_training_cases, dataset_name=dataset_name, description=description)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DlnpUXrMk6t3"
      },
      "outputs": [],
      "source": [
        "os.environ['nnUNet_raw'] = \"/content/nnUNet/nnUNet_raw\"\n",
        "os.environ['nnUNet_preprocessed'] =  \"/content/nnUNet/nnUNet_preprocessed\"\n",
        "os.environ['nnUNet_results'] = \"/content/nnUNet/nnUNet_results\"\n",
        "\n",
        "# Verify dataset integrity has to be executed only the first time you are pre-processing the data\n",
        "# After successful plan and preprocessing\n",
        "!nnUNetv2_plan_and_preprocess -d 101 --verify_dataset_integrity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0Egt2x4mOaC",
        "outputId": "00702b82-2d3e-490e-a71e-c7507cd028b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "############################\n",
            "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
            "############################\n",
            "\n",
            "Using device: cuda:0\n",
            "\n",
            "#######################################################################\n",
            "Please cite the following paper when using nnU-Net:\n",
            "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
            "#######################################################################\n",
            "\n",
            "2024-05-04 08:01:04.374875: do_dummy_2d_data_aug: False\n",
            "2024-05-04 08:01:04.375678: Using splits from existing split file: /content/nnUNET_SELs/nnUNet_SEL/nnUNet_preprocessed/Dataset101_SEL/splits_final.json\n",
            "2024-05-04 08:01:04.375939: The split file contains 5 splits.\n",
            "2024-05-04 08:01:04.376014: Desired fold for training: 0\n",
            "2024-05-04 08:01:04.376065: This split has 84 training and 22 validation cases.\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "using pin_memory on device 0\n",
            "using pin_memory on device 0\n",
            "2024-05-04 08:01:13.300879: Using torch.compile...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
            "\n",
            "This is the configuration used by this training:\n",
            "Configuration name: 3d_fullres\n",
            " {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 112, 160], 'median_image_size_in_voxels': [154.0, 150.5, 197.0], 'spacing': [0.8600000143051147, 0.859375, 0.859375], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 1, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} \n",
            "\n",
            "These are the global plan.json settings:\n",
            " {'dataset_name': 'Dataset101_SEL', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [0.8600000143051147, 0.859375, 0.859375], 'original_median_shape_after_transp': [154, 150, 197], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [2, 0, 1], 'transpose_backward': [1, 2, 0], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 256.0, 'mean': 123.05370330810547, 'median': 121.0, 'min': 0.0, 'percentile_00_5': 62.0, 'percentile_99_5': 206.0, 'std': 28.96869659423828}, '1': {'max': 266.2607116699219, 'mean': 184.99339294433594, 'median': 191.1289825439453, 'min': -3.0133938789367676, 'percentile_00_5': 71.44168853759766, 'percentile_99_5': 246.94969177246094, 'std': 34.90648651123047}}} \n",
            "\n",
            "2024-05-04 08:01:15.372849: unpacking dataset...\n",
            "2024-05-04 08:01:35.585481: unpacking done...\n",
            "2024-05-04 08:01:35.586751: Unable to plot network architecture: nnUNet_compile is enabled!\n",
            "2024-05-04 08:01:35.593335: \n",
            "2024-05-04 08:01:35.593438: Epoch 0\n",
            "2024-05-04 08:01:35.593613: Current learning rate: 0.01\n",
            "2024-05-04 08:05:05.662827: train_loss -0.3092\n",
            "2024-05-04 08:05:05.663165: val_loss -0.5808\n",
            "2024-05-04 08:05:05.663375: Pseudo dice [0.699]\n",
            "2024-05-04 08:05:05.663566: Epoch time: 210.07 s\n",
            "2024-05-04 08:05:05.663769: Yayy! New best EMA pseudo Dice: 0.699\n",
            "2024-05-04 08:05:07.483566: \n",
            "2024-05-04 08:05:07.483716: Epoch 1\n",
            "2024-05-04 08:05:07.483854: Current learning rate: 0.0091\n",
            "2024-05-04 08:07:37.708748: train_loss -0.6237\n",
            "2024-05-04 08:07:37.720243: val_loss -0.6309\n",
            "2024-05-04 08:07:37.720617: Pseudo dice [0.7496]\n",
            "2024-05-04 08:07:37.720871: Epoch time: 150.23 s\n",
            "2024-05-04 08:07:37.721107: Yayy! New best EMA pseudo Dice: 0.7041\n",
            "2024-05-04 08:07:41.671724: \n",
            "2024-05-04 08:07:41.671967: Epoch 2\n",
            "2024-05-04 08:07:41.672153: Current learning rate: 0.00818\n",
            "2024-05-04 08:10:13.020264: train_loss -0.6471\n",
            "2024-05-04 08:10:13.020560: val_loss -0.631\n",
            "2024-05-04 08:10:13.020692: Pseudo dice [0.7592]\n",
            "2024-05-04 08:10:13.020823: Epoch time: 151.35 s\n",
            "2024-05-04 08:10:13.020921: Yayy! New best EMA pseudo Dice: 0.7096\n",
            "2024-05-04 08:10:17.992095: \n",
            "2024-05-04 08:10:17.992310: Epoch 3\n",
            "2024-05-04 08:10:17.992465: Current learning rate: 0.00725\n",
            "2024-05-04 08:12:48.176618: train_loss -0.6551\n",
            "2024-05-04 08:12:48.177093: val_loss -0.6786\n",
            "2024-05-04 08:12:48.177305: Pseudo dice [0.759]\n",
            "2024-05-04 08:12:48.177466: Epoch time: 150.19 s\n",
            "2024-05-04 08:12:48.177593: Yayy! New best EMA pseudo Dice: 0.7146\n",
            "2024-05-04 08:12:51.936986: \n",
            "2024-05-04 08:12:51.937204: Epoch 4\n",
            "2024-05-04 08:12:51.937341: Current learning rate: 0.00631\n",
            "2024-05-04 08:15:31.057827: train_loss -0.667\n",
            "2024-05-04 08:15:31.078520: val_loss -0.6562\n",
            "2024-05-04 08:15:31.078753: Pseudo dice [0.7477]\n",
            "2024-05-04 08:15:31.078881: Epoch time: 159.12 s\n",
            "2024-05-04 08:15:31.078986: Yayy! New best EMA pseudo Dice: 0.7179\n",
            "2024-05-04 08:15:34.697417: \n",
            "2024-05-04 08:15:34.697650: Epoch 5\n",
            "2024-05-04 08:15:34.697795: Current learning rate: 0.00536\n",
            "2024-05-04 08:18:02.521667: train_loss -0.6758\n",
            "2024-05-04 08:18:02.522025: val_loss -0.6801\n",
            "2024-05-04 08:18:02.522213: Pseudo dice [0.7489]\n",
            "2024-05-04 08:18:02.522356: Epoch time: 147.83 s\n",
            "2024-05-04 08:18:02.522489: Yayy! New best EMA pseudo Dice: 0.721\n",
            "2024-05-04 08:18:06.606009: \n",
            "2024-05-04 08:18:06.606461: Epoch 6\n",
            "2024-05-04 08:18:06.606654: Current learning rate: 0.00438\n",
            "2024-05-04 08:20:49.276306: train_loss -0.6911\n",
            "2024-05-04 08:20:49.289588: val_loss -0.666\n",
            "2024-05-04 08:20:49.289844: Pseudo dice [0.7615]\n",
            "2024-05-04 08:20:49.290033: Epoch time: 162.67 s\n",
            "2024-05-04 08:20:49.290170: Yayy! New best EMA pseudo Dice: 0.725\n",
            "2024-05-04 08:20:53.519724: \n",
            "2024-05-04 08:20:53.520142: Epoch 7\n",
            "2024-05-04 08:20:53.520312: Current learning rate: 0.00338\n",
            "2024-05-04 08:23:23.764164: train_loss -0.6948\n",
            "2024-05-04 08:23:23.764492: val_loss -0.6686\n",
            "2024-05-04 08:23:23.764647: Pseudo dice [0.7819]\n",
            "2024-05-04 08:23:23.764766: Epoch time: 150.25 s\n",
            "2024-05-04 08:23:23.764863: Yayy! New best EMA pseudo Dice: 0.7307\n",
            "2024-05-04 08:23:27.835510: \n",
            "2024-05-04 08:23:27.835746: Epoch 8\n",
            "2024-05-04 08:23:27.835940: Current learning rate: 0.00235\n",
            "2024-05-04 08:25:55.995093: train_loss -0.6922\n",
            "2024-05-04 08:25:55.995683: val_loss -0.6659\n",
            "2024-05-04 08:25:55.995827: Pseudo dice [0.7717]\n",
            "2024-05-04 08:25:55.995951: Epoch time: 148.16 s\n",
            "2024-05-04 08:25:55.996089: Yayy! New best EMA pseudo Dice: 0.7348\n",
            "2024-05-04 08:26:00.007435: \n",
            "2024-05-04 08:26:00.007714: Epoch 9\n",
            "2024-05-04 08:26:00.007904: Current learning rate: 0.00126\n",
            "2024-05-04 08:28:30.010430: train_loss -0.693\n",
            "2024-05-04 08:28:30.010717: val_loss -0.6693\n",
            "2024-05-04 08:28:30.010844: Pseudo dice [0.7687]\n",
            "2024-05-04 08:28:30.010981: Epoch time: 150.01 s\n",
            "2024-05-04 08:28:30.011107: Yayy! New best EMA pseudo Dice: 0.7382\n",
            "2024-05-04 08:28:34.913303: Training done.\n",
            "2024-05-04 08:28:35.017273: Using splits from existing split file: /content/nnUNET_SELs/nnUNet_SEL/nnUNet_preprocessed/Dataset101_SEL/splits_final.json\n",
            "2024-05-04 08:28:35.017682: The split file contains 5 splits.\n",
            "2024-05-04 08:28:35.017793: Desired fold for training: 0\n",
            "2024-05-04 08:28:35.017877: This split has 84 training and 22 validation cases.\n",
            "2024-05-04 08:28:35.018306: predicting 013\n",
            "2024-05-04 08:28:35.019691: 013, shape torch.Size([2, 156, 150, 201]), rank 0\n",
            "2024-05-04 08:28:58.527549: predicting 019\n",
            "2024-05-04 08:28:58.529548: 019, shape torch.Size([2, 150, 150, 198]), rank 0\n",
            "2024-05-04 08:28:59.473660: predicting 024\n",
            "2024-05-04 08:28:59.475545: 024, shape torch.Size([2, 152, 148, 191]), rank 0\n",
            "2024-05-04 08:29:00.418899: predicting 030\n",
            "2024-05-04 08:29:00.420865: 030, shape torch.Size([2, 154, 150, 200]), rank 0\n",
            "2024-05-04 08:29:01.365756: predicting 036\n",
            "2024-05-04 08:29:01.367568: 036, shape torch.Size([2, 144, 151, 198]), rank 0\n",
            "2024-05-04 08:29:02.310545: predicting 039\n",
            "2024-05-04 08:29:02.312692: 039, shape torch.Size([2, 158, 150, 202]), rank 0\n",
            "2024-05-04 08:29:03.257410: predicting 044\n",
            "2024-05-04 08:29:03.259382: 044, shape torch.Size([2, 152, 153, 195]), rank 0\n",
            "2024-05-04 08:29:04.203401: predicting 051\n",
            "2024-05-04 08:29:04.206833: 051, shape torch.Size([2, 164, 150, 205]), rank 0\n",
            "2024-05-04 08:29:05.160173: predicting 056\n",
            "2024-05-04 08:29:05.163542: 056, shape torch.Size([2, 156, 158, 207]), rank 0\n",
            "2024-05-04 08:29:06.117629: predicting 057\n",
            "2024-05-04 08:29:06.121293: 057, shape torch.Size([2, 158, 153, 193]), rank 0\n",
            "2024-05-04 08:29:07.073395: predicting 059\n",
            "2024-05-04 08:29:07.076414: 059, shape torch.Size([2, 152, 155, 190]), rank 0\n",
            "2024-05-04 08:29:08.028470: predicting 063\n",
            "2024-05-04 08:29:08.031610: 063, shape torch.Size([2, 158, 155, 194]), rank 0\n",
            "2024-05-04 08:29:08.984008: predicting 064\n",
            "2024-05-04 08:29:08.985937: 064, shape torch.Size([2, 154, 150, 198]), rank 0\n",
            "2024-05-04 08:29:09.938741: predicting 076\n",
            "2024-05-04 08:29:09.941949: 076, shape torch.Size([2, 142, 149, 193]), rank 0\n",
            "2024-05-04 08:29:10.891444: predicting 077\n",
            "2024-05-04 08:29:10.893665: 077, shape torch.Size([2, 142, 148, 191]), rank 0\n",
            "2024-05-04 08:29:11.843785: predicting 084\n",
            "2024-05-04 08:29:11.845808: 084, shape torch.Size([2, 154, 152, 196]), rank 0\n",
            "2024-05-04 08:29:12.798756: predicting 094\n",
            "2024-05-04 08:29:12.800579: 094, shape torch.Size([2, 160, 147, 195]), rank 0\n",
            "2024-05-04 08:29:13.754205: predicting 095\n",
            "2024-05-04 08:29:13.756664: 095, shape torch.Size([2, 175, 153, 200]), rank 0\n",
            "2024-05-04 08:29:14.709253: predicting 103\n",
            "2024-05-04 08:29:14.711598: 103, shape torch.Size([2, 149, 148, 192]), rank 0\n",
            "2024-05-04 08:29:15.653960: predicting 106\n",
            "2024-05-04 08:29:15.656088: 106, shape torch.Size([2, 156, 152, 187]), rank 0\n",
            "2024-05-04 08:29:16.606229: predicting 108\n",
            "2024-05-04 08:29:16.608165: 108, shape torch.Size([2, 149, 148, 197]), rank 0\n",
            "2024-05-04 08:29:17.556150: predicting 109\n",
            "2024-05-04 08:29:17.559057: 109, shape torch.Size([2, 156, 155, 200]), rank 0\n",
            "2024-05-04 08:29:28.976629: Validation complete\n",
            "2024-05-04 08:29:28.976788: Mean Validation Dice:  0.6930109727373129\n"
          ]
        }
      ],
      "source": [
        "!nnUNetv2_train Dataset101_SEL 3d_fullres 0 -tr nnUNetTrainer_10epochs --npz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nnUNetv2_train Dataset101_SEL 3d_fullres 1 -tr nnUNetTrainer_10epochs --npz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmw6uCO8mQKv",
        "outputId": "ee992814-16d6-4921-b99a-a4ccad158271"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "############################\n",
            "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
            "############################\n",
            "\n",
            "Using device: cuda:0\n",
            "\n",
            "#######################################################################\n",
            "Please cite the following paper when using nnU-Net:\n",
            "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
            "#######################################################################\n",
            "\n",
            "2024-05-04 08:29:35.469040: do_dummy_2d_data_aug: False\n",
            "2024-05-04 08:29:35.469932: Using splits from existing split file: /content/nnUNET_SELs/nnUNet_SEL/nnUNet_preprocessed/Dataset101_SEL/splits_final.json\n",
            "2024-05-04 08:29:35.470188: The split file contains 5 splits.\n",
            "2024-05-04 08:29:35.470253: Desired fold for training: 1\n",
            "2024-05-04 08:29:35.470301: This split has 85 training and 21 validation cases.\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "using pin_memory on device 0\n",
            "using pin_memory on device 0\n",
            "2024-05-04 08:29:42.635668: Using torch.compile...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
            "\n",
            "This is the configuration used by this training:\n",
            "Configuration name: 3d_fullres\n",
            " {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 112, 160], 'median_image_size_in_voxels': [154.0, 150.5, 197.0], 'spacing': [0.8600000143051147, 0.859375, 0.859375], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 1, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} \n",
            "\n",
            "These are the global plan.json settings:\n",
            " {'dataset_name': 'Dataset101_SEL', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [0.8600000143051147, 0.859375, 0.859375], 'original_median_shape_after_transp': [154, 150, 197], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [2, 0, 1], 'transpose_backward': [1, 2, 0], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 256.0, 'mean': 123.05370330810547, 'median': 121.0, 'min': 0.0, 'percentile_00_5': 62.0, 'percentile_99_5': 206.0, 'std': 28.96869659423828}, '1': {'max': 266.2607116699219, 'mean': 184.99339294433594, 'median': 191.1289825439453, 'min': -3.0133938789367676, 'percentile_00_5': 71.44168853759766, 'percentile_99_5': 246.94969177246094, 'std': 34.90648651123047}}} \n",
            "\n",
            "2024-05-04 08:29:44.089450: unpacking dataset...\n",
            "2024-05-04 08:29:52.474151: unpacking done...\n",
            "2024-05-04 08:29:52.476358: Unable to plot network architecture: nnUNet_compile is enabled!\n",
            "2024-05-04 08:29:52.484865: \n",
            "2024-05-04 08:29:52.485003: Epoch 0\n",
            "2024-05-04 08:29:52.485214: Current learning rate: 0.01\n",
            "2024-05-04 08:33:04.444134: train_loss -0.0805\n",
            "2024-05-04 08:33:04.444401: val_loss -0.4797\n",
            "2024-05-04 08:33:04.444546: Pseudo dice [0.5604]\n",
            "2024-05-04 08:33:04.444660: Epoch time: 191.96 s\n",
            "2024-05-04 08:33:04.444749: Yayy! New best EMA pseudo Dice: 0.5604\n",
            "2024-05-04 08:33:06.236443: \n",
            "2024-05-04 08:33:06.236611: Epoch 1\n",
            "2024-05-04 08:33:06.236757: Current learning rate: 0.0091\n",
            "2024-05-04 08:35:29.532064: train_loss -0.5348\n",
            "2024-05-04 08:35:29.532377: val_loss -0.5777\n",
            "2024-05-04 08:35:29.532514: Pseudo dice [0.7142]\n",
            "2024-05-04 08:35:29.532650: Epoch time: 143.3 s\n",
            "2024-05-04 08:35:29.532745: Yayy! New best EMA pseudo Dice: 0.5758\n",
            "2024-05-04 08:35:33.651273: \n",
            "2024-05-04 08:35:33.651496: Epoch 2\n",
            "2024-05-04 08:35:33.651659: Current learning rate: 0.00818\n",
            "2024-05-04 08:38:10.925189: train_loss -0.6121\n",
            "2024-05-04 08:38:10.937109: val_loss -0.6247\n",
            "2024-05-04 08:38:10.937376: Pseudo dice [0.7226]\n",
            "2024-05-04 08:38:10.937552: Epoch time: 157.28 s\n",
            "2024-05-04 08:38:10.937686: Yayy! New best EMA pseudo Dice: 0.5905\n",
            "2024-05-04 08:38:15.363336: \n",
            "2024-05-04 08:38:15.363568: Epoch 3\n",
            "2024-05-04 08:38:15.363736: Current learning rate: 0.00725\n",
            "2024-05-04 08:40:51.578859: train_loss -0.6409\n",
            "2024-05-04 08:40:51.592105: val_loss -0.6558\n",
            "2024-05-04 08:40:51.592343: Pseudo dice [0.7393]\n",
            "2024-05-04 08:40:51.592470: Epoch time: 156.22 s\n",
            "2024-05-04 08:40:51.592572: Yayy! New best EMA pseudo Dice: 0.6054\n",
            "2024-05-04 08:40:55.855063: \n",
            "2024-05-04 08:40:55.855322: Epoch 4\n",
            "2024-05-04 08:40:55.855494: Current learning rate: 0.00631\n",
            "2024-05-04 08:43:29.747161: train_loss -0.6447\n",
            "2024-05-04 08:43:29.747503: val_loss -0.6522\n",
            "2024-05-04 08:43:29.747665: Pseudo dice [0.753]\n",
            "2024-05-04 08:43:29.747795: Epoch time: 153.89 s\n",
            "2024-05-04 08:43:29.747900: Yayy! New best EMA pseudo Dice: 0.6201\n",
            "2024-05-04 08:43:33.892283: \n",
            "2024-05-04 08:43:33.892521: Epoch 5\n",
            "2024-05-04 08:43:33.892707: Current learning rate: 0.00536\n",
            "2024-05-04 08:46:07.209260: train_loss -0.6636\n",
            "2024-05-04 08:46:07.221124: val_loss -0.6546\n",
            "2024-05-04 08:46:07.221373: Pseudo dice [0.7536]\n",
            "2024-05-04 08:46:07.221524: Epoch time: 153.32 s\n",
            "2024-05-04 08:46:07.221632: Yayy! New best EMA pseudo Dice: 0.6335\n",
            "2024-05-04 08:46:10.851087: \n",
            "2024-05-04 08:46:10.851317: Epoch 6\n",
            "2024-05-04 08:46:10.851475: Current learning rate: 0.00438\n",
            "2024-05-04 08:48:37.934118: train_loss -0.6645\n",
            "2024-05-04 08:48:37.934507: val_loss -0.6796\n",
            "2024-05-04 08:48:37.934696: Pseudo dice [0.7887]\n",
            "2024-05-04 08:48:37.934842: Epoch time: 147.09 s\n",
            "2024-05-04 08:48:37.934965: Yayy! New best EMA pseudo Dice: 0.649\n",
            "2024-05-04 08:48:42.111260: \n",
            "2024-05-04 08:48:42.111630: Epoch 7\n",
            "2024-05-04 08:48:42.111791: Current learning rate: 0.00338\n",
            "2024-05-04 08:51:16.245354: train_loss -0.6749\n",
            "2024-05-04 08:51:16.245688: val_loss -0.6807\n",
            "2024-05-04 08:51:16.245844: Pseudo dice [0.7736]\n",
            "2024-05-04 08:51:16.246019: Epoch time: 154.14 s\n",
            "2024-05-04 08:51:16.246218: Yayy! New best EMA pseudo Dice: 0.6615\n",
            "2024-05-04 08:51:20.050320: \n",
            "2024-05-04 08:51:20.050500: Epoch 8\n",
            "2024-05-04 08:51:20.050655: Current learning rate: 0.00235\n",
            "2024-05-04 08:53:45.545856: train_loss -0.6672\n",
            "2024-05-04 08:53:45.546165: val_loss -0.6627\n",
            "2024-05-04 08:53:45.546297: Pseudo dice [0.7718]\n",
            "2024-05-04 08:53:45.546432: Epoch time: 145.5 s\n",
            "2024-05-04 08:53:45.546537: Yayy! New best EMA pseudo Dice: 0.6725\n",
            "2024-05-04 08:53:49.542675: \n",
            "2024-05-04 08:53:49.542895: Epoch 9\n",
            "2024-05-04 08:53:49.543068: Current learning rate: 0.00126\n",
            "2024-05-04 08:56:30.727179: train_loss -0.6804\n",
            "2024-05-04 08:56:30.727508: val_loss -0.687\n",
            "2024-05-04 08:56:30.727639: Pseudo dice [0.7628]\n",
            "2024-05-04 08:56:30.727764: Epoch time: 161.19 s\n",
            "2024-05-04 08:56:30.727857: Yayy! New best EMA pseudo Dice: 0.6815\n",
            "2024-05-04 08:56:35.157847: Training done.\n",
            "2024-05-04 08:56:35.224454: Using splits from existing split file: /content/nnUNET_SELs/nnUNet_SEL/nnUNet_preprocessed/Dataset101_SEL/splits_final.json\n",
            "2024-05-04 08:56:35.224879: The split file contains 5 splits.\n",
            "2024-05-04 08:56:35.225005: Desired fold for training: 1\n",
            "2024-05-04 08:56:35.225106: This split has 85 training and 21 validation cases.\n",
            "2024-05-04 08:56:35.225514: predicting 010\n",
            "2024-05-04 08:56:35.226844: 010, shape torch.Size([2, 156, 148, 203]), rank 0\n",
            "2024-05-04 08:56:54.245775: predicting 016\n",
            "2024-05-04 08:56:54.247777: 016, shape torch.Size([2, 166, 157, 207]), rank 0\n",
            "2024-05-04 08:56:55.200236: predicting 018\n",
            "2024-05-04 08:56:55.202966: 018, shape torch.Size([2, 146, 145, 192]), rank 0\n",
            "2024-05-04 08:56:56.149391: predicting 031\n",
            "2024-05-04 08:56:56.151204: 031, shape torch.Size([2, 149, 150, 208]), rank 0\n",
            "2024-05-04 08:56:57.105569: predicting 037\n",
            "2024-05-04 08:56:57.107853: 037, shape torch.Size([2, 154, 148, 194]), rank 0\n",
            "2024-05-04 08:56:58.055273: predicting 041\n",
            "2024-05-04 08:56:58.057194: 041, shape torch.Size([2, 146, 140, 181]), rank 0\n",
            "2024-05-04 08:56:59.002367: predicting 046\n",
            "2024-05-04 08:56:59.005287: 046, shape torch.Size([2, 152, 141, 188]), rank 0\n",
            "2024-05-04 08:56:59.957233: predicting 048\n",
            "2024-05-04 08:56:59.959152: 048, shape torch.Size([2, 152, 151, 202]), rank 0\n",
            "2024-05-04 08:57:00.907673: predicting 050\n",
            "2024-05-04 08:57:00.910827: 050, shape torch.Size([2, 156, 157, 205]), rank 0\n",
            "2024-05-04 08:57:01.869623: predicting 054\n",
            "2024-05-04 08:57:01.871905: 054, shape torch.Size([2, 156, 153, 200]), rank 0\n",
            "2024-05-04 08:57:02.820711: predicting 060\n",
            "2024-05-04 08:57:02.822712: 060, shape torch.Size([2, 156, 152, 198]), rank 0\n",
            "2024-05-04 08:57:03.781820: predicting 061\n",
            "2024-05-04 08:57:03.783752: 061, shape torch.Size([2, 152, 153, 185]), rank 0\n",
            "2024-05-04 08:57:04.740905: predicting 070\n",
            "2024-05-04 08:57:04.742689: 070, shape torch.Size([2, 156, 134, 193]), rank 0\n",
            "2024-05-04 08:57:05.700032: predicting 071\n",
            "2024-05-04 08:57:05.701735: 071, shape torch.Size([2, 149, 148, 197]), rank 0\n",
            "2024-05-04 08:57:06.649959: predicting 073\n",
            "2024-05-04 08:57:06.651976: 073, shape torch.Size([2, 164, 145, 204]), rank 0\n",
            "2024-05-04 08:57:07.602086: predicting 083\n",
            "2024-05-04 08:57:07.604413: 083, shape torch.Size([2, 147, 147, 185]), rank 0\n",
            "2024-05-04 08:57:08.559894: predicting 091\n",
            "2024-05-04 08:57:08.561731: 091, shape torch.Size([2, 158, 141, 192]), rank 0\n",
            "2024-05-04 08:57:09.509085: predicting 092\n",
            "2024-05-04 08:57:09.511238: 092, shape torch.Size([2, 145, 148, 195]), rank 0\n",
            "2024-05-04 08:57:10.468770: predicting 104\n",
            "2024-05-04 08:57:10.470610: 104, shape torch.Size([2, 153, 157, 195]), rank 0\n",
            "2024-05-04 08:57:11.420270: predicting 110\n",
            "2024-05-04 08:57:11.422504: 110, shape torch.Size([2, 154, 146, 203]), rank 0\n",
            "2024-05-04 08:57:12.377671: predicting 116\n",
            "2024-05-04 08:57:12.379564: 116, shape torch.Size([2, 161, 158, 208]), rank 0\n",
            "2024-05-04 08:57:23.699621: Validation complete\n",
            "2024-05-04 08:57:23.699756: Mean Validation Dice:  0.7123090140805486\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nnUNetv2_train Dataset101_SEL 3d_fullres 2 -tr nnUNetTrainer_10epochs --npz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdJfUddfmSnt",
        "outputId": "9b0b9755-25a0-48b0-e93d-bde87d91723b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "############################\n",
            "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
            "############################\n",
            "\n",
            "Using device: cuda:0\n",
            "\n",
            "#######################################################################\n",
            "Please cite the following paper when using nnU-Net:\n",
            "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
            "#######################################################################\n",
            "\n",
            "2024-05-04 08:57:30.432538: do_dummy_2d_data_aug: False\n",
            "2024-05-04 08:57:30.433453: Using splits from existing split file: /content/nnUNET_SELs/nnUNet_SEL/nnUNet_preprocessed/Dataset101_SEL/splits_final.json\n",
            "2024-05-04 08:57:30.433709: The split file contains 5 splits.\n",
            "2024-05-04 08:57:30.433778: Desired fold for training: 2\n",
            "2024-05-04 08:57:30.433845: This split has 85 training and 21 validation cases.\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "using pin_memory on device 0\n",
            "using pin_memory on device 0\n",
            "2024-05-04 08:57:37.598835: Using torch.compile...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
            "\n",
            "This is the configuration used by this training:\n",
            "Configuration name: 3d_fullres\n",
            " {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 112, 160], 'median_image_size_in_voxels': [154.0, 150.5, 197.0], 'spacing': [0.8600000143051147, 0.859375, 0.859375], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 1, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} \n",
            "\n",
            "These are the global plan.json settings:\n",
            " {'dataset_name': 'Dataset101_SEL', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [0.8600000143051147, 0.859375, 0.859375], 'original_median_shape_after_transp': [154, 150, 197], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [2, 0, 1], 'transpose_backward': [1, 2, 0], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 256.0, 'mean': 123.05370330810547, 'median': 121.0, 'min': 0.0, 'percentile_00_5': 62.0, 'percentile_99_5': 206.0, 'std': 28.96869659423828}, '1': {'max': 266.2607116699219, 'mean': 184.99339294433594, 'median': 191.1289825439453, 'min': -3.0133938789367676, 'percentile_00_5': 71.44168853759766, 'percentile_99_5': 246.94969177246094, 'std': 34.90648651123047}}} \n",
            "\n",
            "2024-05-04 08:57:39.186896: unpacking dataset...\n",
            "2024-05-04 08:57:50.807711: unpacking done...\n",
            "2024-05-04 08:57:50.812262: Unable to plot network architecture: nnUNet_compile is enabled!\n",
            "2024-05-04 08:57:50.824480: \n",
            "2024-05-04 08:57:50.824629: Epoch 0\n",
            "2024-05-04 08:57:50.824862: Current learning rate: 0.01\n",
            "2024-05-04 09:00:55.632639: train_loss -0.3554\n",
            "2024-05-04 09:00:55.633062: val_loss -0.587\n",
            "2024-05-04 09:00:55.633305: Pseudo dice [0.7135]\n",
            "2024-05-04 09:00:55.633535: Epoch time: 184.81 s\n",
            "2024-05-04 09:00:55.633727: Yayy! New best EMA pseudo Dice: 0.7135\n",
            "2024-05-04 09:00:57.516458: \n",
            "2024-05-04 09:00:57.516623: Epoch 1\n",
            "2024-05-04 09:00:57.516749: Current learning rate: 0.0091\n",
            "2024-05-04 09:03:33.581904: train_loss -0.6039\n",
            "2024-05-04 09:03:33.582229: val_loss -0.6513\n",
            "2024-05-04 09:03:33.582382: Pseudo dice [0.7506]\n",
            "2024-05-04 09:03:33.582534: Epoch time: 156.07 s\n",
            "2024-05-04 09:03:33.582644: Yayy! New best EMA pseudo Dice: 0.7172\n",
            "2024-05-04 09:03:37.047417: \n",
            "2024-05-04 09:03:37.047660: Epoch 2\n",
            "2024-05-04 09:03:37.047818: Current learning rate: 0.00818\n",
            "2024-05-04 09:06:05.329452: train_loss -0.6303\n",
            "2024-05-04 09:06:05.329861: val_loss -0.6403\n",
            "2024-05-04 09:06:05.330111: Pseudo dice [0.7608]\n",
            "2024-05-04 09:06:05.330296: Epoch time: 148.28 s\n",
            "2024-05-04 09:06:05.330433: Yayy! New best EMA pseudo Dice: 0.7216\n",
            "2024-05-04 09:06:10.327159: \n",
            "2024-05-04 09:06:10.327393: Epoch 3\n",
            "2024-05-04 09:06:10.327557: Current learning rate: 0.00725\n",
            "2024-05-04 09:08:32.262971: train_loss -0.6587\n",
            "2024-05-04 09:08:32.263333: val_loss -0.6562\n",
            "2024-05-04 09:08:32.263474: Pseudo dice [0.7672]\n",
            "2024-05-04 09:08:32.263602: Epoch time: 141.94 s\n",
            "2024-05-04 09:08:32.263697: Yayy! New best EMA pseudo Dice: 0.7261\n",
            "2024-05-04 09:08:36.120916: \n",
            "2024-05-04 09:08:36.121119: Epoch 4\n",
            "2024-05-04 09:08:36.121250: Current learning rate: 0.00631\n",
            "2024-05-04 09:11:07.566931: train_loss -0.6518\n",
            "2024-05-04 09:11:07.567405: val_loss -0.657\n",
            "2024-05-04 09:11:07.567575: Pseudo dice [0.7635]\n",
            "2024-05-04 09:11:07.567699: Epoch time: 151.45 s\n",
            "2024-05-04 09:11:07.567800: Yayy! New best EMA pseudo Dice: 0.7299\n",
            "2024-05-04 09:11:11.802164: \n",
            "2024-05-04 09:11:11.802373: Epoch 5\n",
            "2024-05-04 09:11:11.802538: Current learning rate: 0.00536\n",
            "2024-05-04 09:13:34.339796: train_loss -0.6713\n",
            "2024-05-04 09:13:34.340155: val_loss -0.6708\n",
            "2024-05-04 09:13:34.340300: Pseudo dice [0.7799]\n",
            "2024-05-04 09:13:34.340430: Epoch time: 142.54 s\n",
            "2024-05-04 09:13:34.340536: Yayy! New best EMA pseudo Dice: 0.7349\n",
            "2024-05-04 09:13:38.174768: \n",
            "2024-05-04 09:13:38.175013: Epoch 6\n",
            "2024-05-04 09:13:38.175184: Current learning rate: 0.00438\n",
            "2024-05-04 09:16:11.737938: train_loss -0.6792\n",
            "2024-05-04 09:16:11.751124: val_loss -0.6751\n",
            "2024-05-04 09:16:11.751360: Pseudo dice [0.7636]\n",
            "2024-05-04 09:16:11.751483: Epoch time: 153.57 s\n",
            "2024-05-04 09:16:11.751588: Yayy! New best EMA pseudo Dice: 0.7378\n",
            "2024-05-04 09:16:16.451223: \n",
            "2024-05-04 09:16:16.451429: Epoch 7\n",
            "2024-05-04 09:16:16.451597: Current learning rate: 0.00338\n",
            "2024-05-04 09:18:44.104556: train_loss -0.6939\n",
            "2024-05-04 09:18:44.104856: val_loss -0.6905\n",
            "2024-05-04 09:18:44.105027: Pseudo dice [0.7823]\n",
            "2024-05-04 09:18:44.105177: Epoch time: 147.66 s\n",
            "2024-05-04 09:18:44.105283: Yayy! New best EMA pseudo Dice: 0.7422\n",
            "2024-05-04 09:18:47.915435: \n",
            "2024-05-04 09:18:47.915667: Epoch 8\n",
            "2024-05-04 09:18:47.915818: Current learning rate: 0.00235\n",
            "2024-05-04 09:21:20.548831: train_loss -0.6813\n",
            "2024-05-04 09:21:20.552088: val_loss -0.6986\n",
            "2024-05-04 09:21:20.552347: Pseudo dice [0.8005]\n",
            "2024-05-04 09:21:20.552622: Epoch time: 152.64 s\n",
            "2024-05-04 09:21:20.552834: Yayy! New best EMA pseudo Dice: 0.748\n",
            "2024-05-04 09:21:25.440259: \n",
            "2024-05-04 09:21:25.440466: Epoch 9\n",
            "2024-05-04 09:21:25.440628: Current learning rate: 0.00126\n",
            "2024-05-04 09:24:02.955700: train_loss -0.6898\n",
            "2024-05-04 09:24:02.956019: val_loss -0.6801\n",
            "2024-05-04 09:24:02.956171: Pseudo dice [0.7811]\n",
            "2024-05-04 09:24:02.956307: Epoch time: 157.52 s\n",
            "2024-05-04 09:24:02.956402: Yayy! New best EMA pseudo Dice: 0.7513\n",
            "2024-05-04 09:24:07.676089: Training done.\n",
            "2024-05-04 09:24:07.773103: Using splits from existing split file: /content/nnUNET_SELs/nnUNet_SEL/nnUNet_preprocessed/Dataset101_SEL/splits_final.json\n",
            "2024-05-04 09:24:07.773476: The split file contains 5 splits.\n",
            "2024-05-04 09:24:07.773562: Desired fold for training: 2\n",
            "2024-05-04 09:24:07.773630: This split has 85 training and 21 validation cases.\n",
            "2024-05-04 09:24:07.774030: predicting 007\n",
            "2024-05-04 09:24:07.775246: 007, shape torch.Size([2, 160, 146, 198]), rank 0\n",
            "2024-05-04 09:24:26.264866: predicting 027\n",
            "2024-05-04 09:24:26.267334: 027, shape torch.Size([2, 154, 155, 195]), rank 0\n",
            "2024-05-04 09:24:27.211720: predicting 028\n",
            "2024-05-04 09:24:27.213603: 028, shape torch.Size([2, 152, 151, 200]), rank 0\n",
            "2024-05-04 09:24:28.155731: predicting 029\n",
            "2024-05-04 09:24:28.158019: 029, shape torch.Size([2, 156, 155, 211]), rank 0\n",
            "2024-05-04 09:24:29.103185: predicting 032\n",
            "2024-05-04 09:24:29.105270: 032, shape torch.Size([2, 156, 154, 203]), rank 0\n",
            "2024-05-04 09:24:30.049120: predicting 033\n",
            "2024-05-04 09:24:30.051429: 033, shape torch.Size([2, 158, 146, 200]), rank 0\n",
            "2024-05-04 09:24:30.994334: predicting 035\n",
            "2024-05-04 09:24:30.996375: 035, shape torch.Size([2, 152, 145, 199]), rank 0\n",
            "2024-05-04 09:24:31.938299: predicting 038\n",
            "2024-05-04 09:24:31.940344: 038, shape torch.Size([2, 152, 171, 205]), rank 0\n",
            "2024-05-04 09:24:33.347804: predicting 043\n",
            "2024-05-04 09:24:33.349837: 043, shape torch.Size([2, 159, 146, 184]), rank 0\n",
            "2024-05-04 09:24:34.291532: predicting 058\n",
            "2024-05-04 09:24:34.293673: 058, shape torch.Size([2, 162, 157, 198]), rank 0\n",
            "2024-05-04 09:24:35.245398: predicting 062\n",
            "2024-05-04 09:24:35.247513: 062, shape torch.Size([2, 156, 146, 199]), rank 0\n",
            "2024-05-04 09:24:36.191211: predicting 066\n",
            "2024-05-04 09:24:36.193355: 066, shape torch.Size([2, 162, 161, 206]), rank 0\n",
            "2024-05-04 09:24:37.153825: predicting 079\n",
            "2024-05-04 09:24:37.156219: 079, shape torch.Size([2, 152, 155, 204]), rank 0\n",
            "2024-05-04 09:24:38.109045: predicting 080\n",
            "2024-05-04 09:24:38.111020: 080, shape torch.Size([2, 144, 155, 191]), rank 0\n",
            "2024-05-04 09:24:39.072801: predicting 081\n",
            "2024-05-04 09:24:39.074976: 081, shape torch.Size([2, 152, 157, 212]), rank 0\n",
            "2024-05-04 09:24:40.026423: predicting 099\n",
            "2024-05-04 09:24:40.028672: 099, shape torch.Size([2, 158, 155, 204]), rank 0\n",
            "2024-05-04 09:24:40.976374: predicting 100\n",
            "2024-05-04 09:24:40.978553: 100, shape torch.Size([2, 146, 146, 184]), rank 0\n",
            "2024-05-04 09:24:41.921201: predicting 101\n",
            "2024-05-04 09:24:41.923215: 101, shape torch.Size([2, 161, 155, 204]), rank 0\n",
            "2024-05-04 09:24:42.870117: predicting 102\n",
            "2024-05-04 09:24:42.872514: 102, shape torch.Size([2, 147, 155, 193]), rank 0\n",
            "2024-05-04 09:24:43.815381: predicting 105\n",
            "2024-05-04 09:24:43.817276: 105, shape torch.Size([2, 150, 144, 185]), rank 0\n",
            "2024-05-04 09:24:44.767114: predicting 121\n",
            "2024-05-04 09:24:44.768796: 121, shape torch.Size([2, 150, 151, 189]), rank 0\n",
            "2024-05-04 09:24:55.662888: Validation complete\n",
            "2024-05-04 09:24:55.663206: Mean Validation Dice:  0.7124740887481293\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nnUNetv2_train Dataset101_SEL 3d_fullres 3 -tr nnUNetTrainer_10epochs --npz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0gSgwqAmTwU",
        "outputId": "17757285-fee4-42d1-bb44-0c1336fc18f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "############################\n",
            "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
            "############################\n",
            "\n",
            "Using device: cuda:0\n",
            "\n",
            "#######################################################################\n",
            "Please cite the following paper when using nnU-Net:\n",
            "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
            "#######################################################################\n",
            "\n",
            "2024-05-04 09:25:02.326064: do_dummy_2d_data_aug: False\n",
            "2024-05-04 09:25:02.326958: Using splits from existing split file: /content/nnUNET_SELs/nnUNet_SEL/nnUNet_preprocessed/Dataset101_SEL/splits_final.json\n",
            "2024-05-04 09:25:02.327195: The split file contains 5 splits.\n",
            "2024-05-04 09:25:02.327255: Desired fold for training: 3\n",
            "2024-05-04 09:25:02.327303: This split has 85 training and 21 validation cases.\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "using pin_memory on device 0\n",
            "using pin_memory on device 0\n",
            "2024-05-04 09:25:10.043321: Using torch.compile...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
            "\n",
            "This is the configuration used by this training:\n",
            "Configuration name: 3d_fullres\n",
            " {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 112, 160], 'median_image_size_in_voxels': [154.0, 150.5, 197.0], 'spacing': [0.8600000143051147, 0.859375, 0.859375], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 1, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} \n",
            "\n",
            "These are the global plan.json settings:\n",
            " {'dataset_name': 'Dataset101_SEL', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [0.8600000143051147, 0.859375, 0.859375], 'original_median_shape_after_transp': [154, 150, 197], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [2, 0, 1], 'transpose_backward': [1, 2, 0], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 256.0, 'mean': 123.05370330810547, 'median': 121.0, 'min': 0.0, 'percentile_00_5': 62.0, 'percentile_99_5': 206.0, 'std': 28.96869659423828}, '1': {'max': 266.2607116699219, 'mean': 184.99339294433594, 'median': 191.1289825439453, 'min': -3.0133938789367676, 'percentile_00_5': 71.44168853759766, 'percentile_99_5': 246.94969177246094, 'std': 34.90648651123047}}} \n",
            "\n",
            "2024-05-04 09:25:11.813934: unpacking dataset...\n",
            "2024-05-04 09:25:21.873474: unpacking done...\n",
            "2024-05-04 09:25:21.874919: Unable to plot network architecture: nnUNet_compile is enabled!\n",
            "2024-05-04 09:25:21.881954: \n",
            "2024-05-04 09:25:21.882099: Epoch 0\n",
            "2024-05-04 09:25:21.882311: Current learning rate: 0.01\n",
            "2024-05-04 09:28:36.526523: train_loss -0.333\n",
            "2024-05-04 09:28:36.526771: val_loss -0.5015\n",
            "2024-05-04 09:28:36.526891: Pseudo dice [0.5503]\n",
            "2024-05-04 09:28:36.527031: Epoch time: 194.65 s\n",
            "2024-05-04 09:28:36.527138: Yayy! New best EMA pseudo Dice: 0.5503\n",
            "2024-05-04 09:28:38.331805: \n",
            "2024-05-04 09:28:38.331976: Epoch 1\n",
            "2024-05-04 09:28:38.332134: Current learning rate: 0.0091\n",
            "2024-05-04 09:31:10.380826: train_loss -0.574\n",
            "2024-05-04 09:31:10.381152: val_loss -0.5649\n",
            "2024-05-04 09:31:10.381286: Pseudo dice [0.704]\n",
            "2024-05-04 09:31:10.381424: Epoch time: 152.05 s\n",
            "2024-05-04 09:31:10.381522: Yayy! New best EMA pseudo Dice: 0.5657\n",
            "2024-05-04 09:31:14.689970: \n",
            "2024-05-04 09:31:14.690191: Epoch 2\n",
            "2024-05-04 09:31:14.690346: Current learning rate: 0.00818\n",
            "2024-05-04 09:33:39.462555: train_loss -0.6208\n",
            "2024-05-04 09:33:39.462856: val_loss -0.6369\n",
            "2024-05-04 09:33:39.463007: Pseudo dice [0.7449]\n",
            "2024-05-04 09:33:39.463164: Epoch time: 144.77 s\n",
            "2024-05-04 09:33:39.463273: Yayy! New best EMA pseudo Dice: 0.5836\n",
            "2024-05-04 09:33:44.006855: \n",
            "2024-05-04 09:33:44.007107: Epoch 3\n",
            "2024-05-04 09:33:44.007272: Current learning rate: 0.00725\n",
            "2024-05-04 09:36:17.577637: train_loss -0.6313\n",
            "2024-05-04 09:36:17.577970: val_loss -0.6447\n",
            "2024-05-04 09:36:17.578197: Pseudo dice [0.7735]\n",
            "2024-05-04 09:36:17.578347: Epoch time: 153.57 s\n",
            "2024-05-04 09:36:17.578474: Yayy! New best EMA pseudo Dice: 0.6026\n",
            "2024-05-04 09:36:22.132628: \n",
            "2024-05-04 09:36:22.132893: Epoch 4\n",
            "2024-05-04 09:36:22.133102: Current learning rate: 0.00631\n",
            "2024-05-04 09:38:54.869879: train_loss -0.6545\n",
            "2024-05-04 09:38:54.870239: val_loss -0.6571\n",
            "2024-05-04 09:38:54.870392: Pseudo dice [0.778]\n",
            "2024-05-04 09:38:54.870517: Epoch time: 152.74 s\n",
            "2024-05-04 09:38:54.870620: Yayy! New best EMA pseudo Dice: 0.6201\n",
            "2024-05-04 09:38:58.518829: \n",
            "2024-05-04 09:38:58.519067: Epoch 5\n",
            "2024-05-04 09:38:58.519232: Current learning rate: 0.00536\n",
            "2024-05-04 09:41:37.222286: train_loss -0.6632\n",
            "2024-05-04 09:41:37.225876: val_loss -0.6647\n",
            "2024-05-04 09:41:37.226115: Pseudo dice [0.7932]\n",
            "2024-05-04 09:41:37.226271: Epoch time: 158.71 s\n",
            "2024-05-04 09:41:37.226394: Yayy! New best EMA pseudo Dice: 0.6374\n",
            "2024-05-04 09:41:41.311045: \n",
            "2024-05-04 09:41:41.311276: Epoch 6\n",
            "2024-05-04 09:41:41.311446: Current learning rate: 0.00438\n",
            "2024-05-04 09:44:13.922407: train_loss -0.6726\n",
            "2024-05-04 09:44:13.963332: val_loss -0.6549\n",
            "2024-05-04 09:44:13.963510: Pseudo dice [0.7719]\n",
            "2024-05-04 09:44:13.963669: Epoch time: 152.61 s\n",
            "2024-05-04 09:44:13.963782: Yayy! New best EMA pseudo Dice: 0.6509\n",
            "2024-05-04 09:44:17.559612: \n",
            "2024-05-04 09:44:17.559826: Epoch 7\n",
            "2024-05-04 09:44:17.560019: Current learning rate: 0.00338\n",
            "2024-05-04 09:46:44.940473: train_loss -0.6841\n",
            "2024-05-04 09:46:44.949423: val_loss -0.6656\n",
            "2024-05-04 09:46:44.949726: Pseudo dice [0.7678]\n",
            "2024-05-04 09:46:44.958109: Epoch time: 147.38 s\n",
            "2024-05-04 09:46:44.958326: Yayy! New best EMA pseudo Dice: 0.6626\n",
            "2024-05-04 09:46:49.022675: \n",
            "2024-05-04 09:46:49.022895: Epoch 8\n",
            "2024-05-04 09:46:49.023082: Current learning rate: 0.00235\n",
            "2024-05-04 09:49:19.214620: train_loss -0.6796\n",
            "2024-05-04 09:49:19.215133: val_loss -0.6714\n",
            "2024-05-04 09:49:19.215407: Pseudo dice [0.7942]\n",
            "2024-05-04 09:49:19.215633: Epoch time: 150.19 s\n",
            "2024-05-04 09:49:19.215824: Yayy! New best EMA pseudo Dice: 0.6757\n",
            "2024-05-04 09:49:23.414725: \n",
            "2024-05-04 09:49:23.414929: Epoch 9\n",
            "2024-05-04 09:49:23.415116: Current learning rate: 0.00126\n",
            "2024-05-04 09:51:48.988039: train_loss -0.6837\n",
            "2024-05-04 09:51:48.988350: val_loss -0.6969\n",
            "2024-05-04 09:51:48.988491: Pseudo dice [0.8014]\n",
            "2024-05-04 09:51:48.988626: Epoch time: 145.58 s\n",
            "2024-05-04 09:51:48.988734: Yayy! New best EMA pseudo Dice: 0.6883\n",
            "2024-05-04 09:51:53.652626: Training done.\n",
            "2024-05-04 09:51:53.730855: Using splits from existing split file: /content/nnUNET_SELs/nnUNet_SEL/nnUNet_preprocessed/Dataset101_SEL/splits_final.json\n",
            "2024-05-04 09:51:53.731266: The split file contains 5 splits.\n",
            "2024-05-04 09:51:53.731362: Desired fold for training: 3\n",
            "2024-05-04 09:51:53.731422: This split has 85 training and 21 validation cases.\n",
            "2024-05-04 09:51:53.731816: predicting 011\n",
            "2024-05-04 09:51:53.733098: 011, shape torch.Size([2, 160, 147, 183]), rank 0\n",
            "2024-05-04 09:52:13.712227: predicting 014\n",
            "2024-05-04 09:52:13.714328: 014, shape torch.Size([2, 148, 143, 191]), rank 0\n",
            "2024-05-04 09:52:14.678979: predicting 023\n",
            "2024-05-04 09:52:14.680744: 023, shape torch.Size([2, 162, 163, 207]), rank 0\n",
            "2024-05-04 09:52:15.659887: predicting 026\n",
            "2024-05-04 09:52:15.661890: 026, shape torch.Size([2, 150, 151, 196]), rank 0\n",
            "2024-05-04 09:52:16.626605: predicting 034\n",
            "2024-05-04 09:52:16.628351: 034, shape torch.Size([2, 156, 152, 199]), rank 0\n",
            "2024-05-04 09:52:17.601083: predicting 042\n",
            "2024-05-04 09:52:17.603183: 042, shape torch.Size([2, 144, 151, 198]), rank 0\n",
            "2024-05-04 09:52:18.567176: predicting 055\n",
            "2024-05-04 09:52:18.569597: 055, shape torch.Size([2, 140, 149, 186]), rank 0\n",
            "2024-05-04 09:52:19.531804: predicting 065\n",
            "2024-05-04 09:52:19.533577: 065, shape torch.Size([2, 158, 166, 202]), rank 0\n",
            "2024-05-04 09:52:20.501270: predicting 067\n",
            "2024-05-04 09:52:20.504837: 067, shape torch.Size([2, 148, 153, 198]), rank 0\n",
            "2024-05-04 09:52:21.477139: predicting 068\n",
            "2024-05-04 09:52:21.480107: 068, shape torch.Size([2, 152, 158, 197]), rank 0\n",
            "2024-05-04 09:52:22.461299: predicting 075\n",
            "2024-05-04 09:52:22.463163: 075, shape torch.Size([2, 161, 153, 202]), rank 0\n",
            "2024-05-04 09:52:23.440482: predicting 078\n",
            "2024-05-04 09:52:23.442704: 078, shape torch.Size([2, 150, 146, 193]), rank 0\n",
            "2024-05-04 09:52:24.406781: predicting 082\n",
            "2024-05-04 09:52:24.408638: 082, shape torch.Size([2, 160, 153, 195]), rank 0\n",
            "2024-05-04 09:52:25.375098: predicting 087\n",
            "2024-05-04 09:52:25.377016: 087, shape torch.Size([2, 150, 148, 200]), rank 0\n",
            "2024-05-04 09:52:26.341854: predicting 088\n",
            "2024-05-04 09:52:26.343700: 088, shape torch.Size([2, 158, 155, 200]), rank 0\n",
            "2024-05-04 09:52:27.310867: predicting 090\n",
            "2024-05-04 09:52:27.314294: 090, shape torch.Size([2, 148, 157, 195]), rank 0\n",
            "2024-05-04 09:52:28.280378: predicting 111\n",
            "2024-05-04 09:52:28.283659: 111, shape torch.Size([2, 154, 149, 204]), rank 0\n",
            "2024-05-04 09:52:29.256038: predicting 115\n",
            "2024-05-04 09:52:29.258912: 115, shape torch.Size([2, 150, 150, 190]), rank 0\n",
            "2024-05-04 09:52:30.225271: predicting 120\n",
            "2024-05-04 09:52:30.227028: 120, shape torch.Size([2, 144, 147, 193]), rank 0\n",
            "2024-05-04 09:52:31.191536: predicting 125\n",
            "2024-05-04 09:52:31.193370: 125, shape torch.Size([2, 152, 146, 185]), rank 0\n",
            "2024-05-04 09:52:32.172071: predicting 126\n",
            "2024-05-04 09:52:32.174084: 126, shape torch.Size([2, 168, 159, 195]), rank 0\n",
            "2024-05-04 09:52:43.443582: Validation complete\n",
            "2024-05-04 09:52:43.443717: Mean Validation Dice:  0.7161822496301207\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nnUNetv2_train Dataset101_SEL 3d_fullres 4 -tr nnUNetTrainer_10epochs --npz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWRAoAyumUp9",
        "outputId": "eb3ddc3e-5622-4680-e65f-165a477cea26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "############################\n",
            "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
            "############################\n",
            "\n",
            "Using device: cuda:0\n",
            "\n",
            "#######################################################################\n",
            "Please cite the following paper when using nnU-Net:\n",
            "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
            "#######################################################################\n",
            "\n",
            "2024-05-04 09:52:50.068980: do_dummy_2d_data_aug: False\n",
            "2024-05-04 09:52:50.069880: Using splits from existing split file: /content/nnUNET_SELs/nnUNet_SEL/nnUNet_preprocessed/Dataset101_SEL/splits_final.json\n",
            "2024-05-04 09:52:50.070134: The split file contains 5 splits.\n",
            "2024-05-04 09:52:50.070198: Desired fold for training: 4\n",
            "2024-05-04 09:52:50.070246: This split has 85 training and 21 validation cases.\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "using pin_memory on device 0\n",
            "using pin_memory on device 0\n",
            "2024-05-04 09:52:57.182327: Using torch.compile...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
            "\n",
            "This is the configuration used by this training:\n",
            "Configuration name: 3d_fullres\n",
            " {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 112, 160], 'median_image_size_in_voxels': [154.0, 150.5, 197.0], 'spacing': [0.8600000143051147, 0.859375, 0.859375], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 1, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} \n",
            "\n",
            "These are the global plan.json settings:\n",
            " {'dataset_name': 'Dataset101_SEL', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [0.8600000143051147, 0.859375, 0.859375], 'original_median_shape_after_transp': [154, 150, 197], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [2, 0, 1], 'transpose_backward': [1, 2, 0], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 256.0, 'mean': 123.05370330810547, 'median': 121.0, 'min': 0.0, 'percentile_00_5': 62.0, 'percentile_99_5': 206.0, 'std': 28.96869659423828}, '1': {'max': 266.2607116699219, 'mean': 184.99339294433594, 'median': 191.1289825439453, 'min': -3.0133938789367676, 'percentile_00_5': 71.44168853759766, 'percentile_99_5': 246.94969177246094, 'std': 34.90648651123047}}} \n",
            "\n",
            "2024-05-04 09:52:59.046299: unpacking dataset...\n",
            "2024-05-04 09:53:09.845399: unpacking done...\n",
            "2024-05-04 09:53:09.847682: Unable to plot network architecture: nnUNet_compile is enabled!\n",
            "2024-05-04 09:53:09.857666: \n",
            "2024-05-04 09:53:09.857863: Epoch 0\n",
            "2024-05-04 09:53:09.858095: Current learning rate: 0.01\n",
            "2024-05-04 09:56:07.734686: train_loss -0.2674\n",
            "2024-05-04 09:56:07.734961: val_loss -0.6122\n",
            "2024-05-04 09:56:07.735137: Pseudo dice [0.6766]\n",
            "2024-05-04 09:56:07.735260: Epoch time: 177.88 s\n",
            "2024-05-04 09:56:07.735360: Yayy! New best EMA pseudo Dice: 0.6766\n",
            "2024-05-04 09:56:09.488891: \n",
            "2024-05-04 09:56:09.489317: Epoch 1\n",
            "2024-05-04 09:56:09.489483: Current learning rate: 0.0091\n",
            "2024-05-04 09:58:39.576440: train_loss -0.6028\n",
            "2024-05-04 09:58:39.576763: val_loss -0.6354\n",
            "2024-05-04 09:58:39.576911: Pseudo dice [0.727]\n",
            "2024-05-04 09:58:39.577066: Epoch time: 150.09 s\n",
            "2024-05-04 09:58:39.577176: Yayy! New best EMA pseudo Dice: 0.6816\n",
            "2024-05-04 09:58:43.121942: \n",
            "2024-05-04 09:58:43.122167: Epoch 2\n",
            "2024-05-04 09:58:43.122317: Current learning rate: 0.00818\n",
            "2024-05-04 10:01:15.720592: train_loss -0.6387\n",
            "2024-05-04 10:01:15.720984: val_loss -0.6511\n",
            "2024-05-04 10:01:15.721159: Pseudo dice [0.7295]\n",
            "2024-05-04 10:01:15.721274: Epoch time: 152.6 s\n",
            "2024-05-04 10:01:15.721368: Yayy! New best EMA pseudo Dice: 0.6864\n",
            "2024-05-04 10:01:20.532542: \n",
            "2024-05-04 10:01:20.532765: Epoch 3\n",
            "2024-05-04 10:01:20.532911: Current learning rate: 0.00725\n",
            "2024-05-04 10:03:46.340751: train_loss -0.6469\n",
            "2024-05-04 10:03:46.341101: val_loss -0.6922\n",
            "2024-05-04 10:03:46.341244: Pseudo dice [0.7614]\n",
            "2024-05-04 10:03:46.341371: Epoch time: 145.81 s\n",
            "2024-05-04 10:03:46.341469: Yayy! New best EMA pseudo Dice: 0.6939\n",
            "2024-05-04 10:03:50.089473: \n",
            "2024-05-04 10:03:50.089680: Epoch 4\n",
            "2024-05-04 10:03:50.089838: Current learning rate: 0.00631\n",
            "2024-05-04 10:06:28.962840: train_loss -0.6496\n",
            "2024-05-04 10:06:28.963142: val_loss -0.6455\n",
            "2024-05-04 10:06:28.963281: Pseudo dice [0.7125]\n",
            "2024-05-04 10:06:28.974036: Epoch time: 158.88 s\n",
            "2024-05-04 10:06:28.974287: Yayy! New best EMA pseudo Dice: 0.6958\n",
            "2024-05-04 10:06:32.757061: \n",
            "2024-05-04 10:06:32.757280: Epoch 5\n",
            "2024-05-04 10:06:32.757438: Current learning rate: 0.00536\n",
            "2024-05-04 10:08:52.131114: train_loss -0.6477\n",
            "2024-05-04 10:08:52.131425: val_loss -0.6946\n",
            "2024-05-04 10:08:52.131573: Pseudo dice [0.7522]\n",
            "2024-05-04 10:08:52.131706: Epoch time: 139.38 s\n",
            "2024-05-04 10:08:52.131808: Yayy! New best EMA pseudo Dice: 0.7014\n",
            "2024-05-04 10:08:56.099681: \n",
            "2024-05-04 10:08:56.099940: Epoch 6\n",
            "2024-05-04 10:08:56.100129: Current learning rate: 0.00438\n",
            "2024-05-04 10:11:45.662245: train_loss -0.673\n",
            "2024-05-04 10:11:45.662570: val_loss -0.6903\n",
            "2024-05-04 10:11:45.662713: Pseudo dice [0.7505]\n",
            "2024-05-04 10:11:45.662842: Epoch time: 169.56 s\n",
            "2024-05-04 10:11:45.662945: Yayy! New best EMA pseudo Dice: 0.7063\n",
            "2024-05-04 10:11:49.669640: \n",
            "2024-05-04 10:11:49.669888: Epoch 7\n",
            "2024-05-04 10:11:49.670118: Current learning rate: 0.00338\n",
            "2024-05-04 10:14:30.095627: train_loss -0.683\n",
            "2024-05-04 10:14:30.095941: val_loss -0.6962\n",
            "2024-05-04 10:14:30.096122: Pseudo dice [0.7543]\n",
            "2024-05-04 10:14:30.096253: Epoch time: 160.43 s\n",
            "2024-05-04 10:14:30.096349: Yayy! New best EMA pseudo Dice: 0.7111\n",
            "2024-05-04 10:14:34.558774: \n",
            "2024-05-04 10:14:34.559019: Epoch 8\n",
            "2024-05-04 10:14:34.559187: Current learning rate: 0.00235\n",
            "2024-05-04 10:17:06.033935: train_loss -0.6762\n",
            "2024-05-04 10:17:06.043110: val_loss -0.7091\n",
            "2024-05-04 10:17:06.043324: Pseudo dice [0.7746]\n",
            "2024-05-04 10:17:06.043463: Epoch time: 151.48 s\n",
            "2024-05-04 10:17:06.043573: Yayy! New best EMA pseudo Dice: 0.7175\n",
            "2024-05-04 10:17:10.371176: \n",
            "2024-05-04 10:17:10.371410: Epoch 9\n",
            "2024-05-04 10:17:10.371580: Current learning rate: 0.00126\n",
            "2024-05-04 10:19:37.497601: train_loss -0.6741\n",
            "2024-05-04 10:19:37.497892: val_loss -0.6823\n",
            "2024-05-04 10:19:37.498054: Pseudo dice [0.7495]\n",
            "2024-05-04 10:19:37.498204: Epoch time: 147.13 s\n",
            "2024-05-04 10:19:37.498320: Yayy! New best EMA pseudo Dice: 0.7207\n",
            "2024-05-04 10:19:42.197499: Training done.\n",
            "2024-05-04 10:19:42.259739: Using splits from existing split file: /content/nnUNET_SELs/nnUNet_SEL/nnUNet_preprocessed/Dataset101_SEL/splits_final.json\n",
            "2024-05-04 10:19:42.261942: The split file contains 5 splits.\n",
            "2024-05-04 10:19:42.262090: Desired fold for training: 4\n",
            "2024-05-04 10:19:42.262184: This split has 85 training and 21 validation cases.\n",
            "2024-05-04 10:19:42.262609: predicting 009\n",
            "2024-05-04 10:19:42.264011: 009, shape torch.Size([2, 156, 157, 205]), rank 0\n",
            "2024-05-04 10:20:01.621402: predicting 017\n",
            "2024-05-04 10:20:01.623394: 017, shape torch.Size([2, 159, 155, 209]), rank 0\n",
            "2024-05-04 10:20:02.583723: predicting 021\n",
            "2024-05-04 10:20:02.585640: 021, shape torch.Size([2, 145, 146, 192]), rank 0\n",
            "2024-05-04 10:20:03.530272: predicting 022\n",
            "2024-05-04 10:20:03.532031: 022, shape torch.Size([2, 158, 146, 200]), rank 0\n",
            "2024-05-04 10:20:04.478373: predicting 025\n",
            "2024-05-04 10:20:04.480244: 025, shape torch.Size([2, 150, 143, 186]), rank 0\n",
            "2024-05-04 10:20:05.425233: predicting 040\n",
            "2024-05-04 10:20:05.427001: 040, shape torch.Size([2, 161, 145, 189]), rank 0\n",
            "2024-05-04 10:20:06.374055: predicting 045\n",
            "2024-05-04 10:20:06.375977: 045, shape torch.Size([2, 156, 147, 188]), rank 0\n",
            "2024-05-04 10:20:07.321148: predicting 047\n",
            "2024-05-04 10:20:07.323200: 047, shape torch.Size([2, 146, 154, 197]), rank 0\n",
            "2024-05-04 10:20:08.274976: predicting 049\n",
            "2024-05-04 10:20:08.276788: 049, shape torch.Size([2, 159, 151, 202]), rank 0\n",
            "2024-05-04 10:20:09.224971: predicting 053\n",
            "2024-05-04 10:20:09.226890: 053, shape torch.Size([2, 161, 146, 185]), rank 0\n",
            "2024-05-04 10:20:10.173052: predicting 072\n",
            "2024-05-04 10:20:10.175060: 072, shape torch.Size([2, 145, 150, 197]), rank 0\n",
            "2024-05-04 10:20:11.121495: predicting 089\n",
            "2024-05-04 10:20:11.123324: 089, shape torch.Size([2, 161, 155, 197]), rank 0\n",
            "2024-05-04 10:20:12.072080: predicting 093\n",
            "2024-05-04 10:20:12.073985: 093, shape torch.Size([2, 154, 146, 195]), rank 0\n",
            "2024-05-04 10:20:13.020365: predicting 096\n",
            "2024-05-04 10:20:13.022183: 096, shape torch.Size([2, 158, 161, 200]), rank 0\n",
            "2024-05-04 10:20:13.971083: predicting 097\n",
            "2024-05-04 10:20:13.973429: 097, shape torch.Size([2, 156, 145, 200]), rank 0\n",
            "2024-05-04 10:20:14.920734: predicting 098\n",
            "2024-05-04 10:20:14.922662: 098, shape torch.Size([2, 150, 146, 193]), rank 0\n",
            "2024-05-04 10:20:15.875364: predicting 107\n",
            "2024-05-04 10:20:15.877210: 107, shape torch.Size([2, 153, 143, 184]), rank 0\n",
            "2024-05-04 10:20:16.822855: predicting 119\n",
            "2024-05-04 10:20:16.824901: 119, shape torch.Size([2, 147, 155, 188]), rank 0\n",
            "2024-05-04 10:20:17.771111: predicting 122\n",
            "2024-05-04 10:20:17.772851: 122, shape torch.Size([2, 158, 153, 195]), rank 0\n",
            "2024-05-04 10:20:18.721104: predicting 123\n",
            "2024-05-04 10:20:18.722958: 123, shape torch.Size([2, 160, 159, 202]), rank 0\n",
            "2024-05-04 10:20:19.684627: predicting 124\n",
            "2024-05-04 10:20:19.686582: 124, shape torch.Size([2, 152, 149, 203]), rank 0\n",
            "2024-05-04 10:20:30.843154: Validation complete\n",
            "2024-05-04 10:20:30.843289: Mean Validation Dice:  0.7273112019413416\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nnUNetv2_predict -d Dataset101_SEL -i /content/nnUNet_SEL/nnUNet_raw/Dataset101_SEL/imagesTs -o /content/nnUNet_SEL/nnUNet_results/Dataset101_SEL/inference -f  0 1 2 3 4 -tr nnUNetTrainer_10epochs -c 3d_fullres -p nnUNetPlans"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eo3JqI6iKHZU",
        "outputId": "b1eefbee-0275-4cf2-b025-d069a12bc3b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "#######################################################################\n",
            "Please cite the following paper when using nnU-Net:\n",
            "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
            "#######################################################################\n",
            "\n",
            "There are 20 cases in the source folder\n",
            "I am process 0 out of 1 (max process ID is 0, we start counting with 0!)\n",
            "There are 20 cases that I would like to predict\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\n",
            "Predicting 131:\n",
            "perform_everything_on_device: True\n",
            "100% 8/8 [00:06<00:00,  1.29it/s]\n",
            "100% 8/8 [00:04<00:00,  2.00it/s]\n",
            "100% 8/8 [00:04<00:00,  1.99it/s]\n",
            "100% 8/8 [00:04<00:00,  1.99it/s]\n",
            "100% 8/8 [00:04<00:00,  1.98it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with 131\n",
            "\n",
            "Predicting 132:\n",
            "perform_everything_on_device: True\n",
            "100% 8/8 [00:04<00:00,  1.98it/s]\n",
            "100% 8/8 [00:04<00:00,  1.98it/s]\n",
            "100% 8/8 [00:04<00:00,  1.97it/s]\n",
            "100% 8/8 [00:04<00:00,  1.97it/s]\n",
            "100% 8/8 [00:04<00:00,  1.96it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with 132\n",
            "\n",
            "Predicting 147:\n",
            "perform_everything_on_device: True\n",
            "100% 8/8 [00:04<00:00,  1.96it/s]\n",
            "100% 8/8 [00:04<00:00,  1.95it/s]\n",
            "100% 8/8 [00:04<00:00,  1.95it/s]\n",
            "100% 8/8 [00:04<00:00,  1.94it/s]\n",
            "100% 8/8 [00:04<00:00,  1.93it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with 147\n",
            "\n",
            "Predicting 148:\n",
            "perform_everything_on_device: True\n",
            "100% 8/8 [00:04<00:00,  1.93it/s]\n",
            "100% 8/8 [00:04<00:00,  1.93it/s]\n",
            "100% 8/8 [00:04<00:00,  1.92it/s]\n",
            "100% 8/8 [00:04<00:00,  1.92it/s]\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with 148\n",
            "\n",
            "Predicting 149:\n",
            "perform_everything_on_device: True\n",
            "100% 8/8 [00:04<00:00,  1.90it/s]\n",
            "100% 8/8 [00:04<00:00,  1.90it/s]\n",
            "100% 8/8 [00:04<00:00,  1.89it/s]\n",
            "100% 8/8 [00:04<00:00,  1.89it/s]\n",
            "100% 8/8 [00:04<00:00,  1.90it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with 149\n",
            "\n",
            "Predicting 151:\n",
            "perform_everything_on_device: True\n",
            "100% 8/8 [00:04<00:00,  1.90it/s]\n",
            "100% 8/8 [00:04<00:00,  1.90it/s]\n",
            "100% 8/8 [00:04<00:00,  1.90it/s]\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with 151\n",
            "\n",
            "Predicting 153:\n",
            "perform_everything_on_device: True\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with 153\n",
            "\n",
            "Predicting 154:\n",
            "perform_everything_on_device: True\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "100% 8/8 [00:04<00:00,  1.92it/s]\n",
            "100% 8/8 [00:04<00:00,  1.92it/s]\n",
            "100% 8/8 [00:04<00:00,  1.92it/s]\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with 154\n",
            "\n",
            "Predicting 155:\n",
            "perform_everything_on_device: True\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with 155\n",
            "\n",
            "Predicting 157:\n",
            "perform_everything_on_device: True\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with 157\n",
            "\n",
            "Predicting 158:\n",
            "perform_everything_on_device: True\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with 158\n",
            "\n",
            "Predicting 159:\n",
            "perform_everything_on_device: True\n",
            "100% 8/8 [00:04<00:00,  1.92it/s]\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with 159\n",
            "\n",
            "Predicting 160:\n",
            "perform_everything_on_device: True\n",
            "100% 8/8 [00:04<00:00,  1.92it/s]\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with 160\n",
            "\n",
            "Predicting 161:\n",
            "perform_everything_on_device: True\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with 161\n",
            "\n",
            "Predicting 165:\n",
            "perform_everything_on_device: True\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "100% 8/8 [00:04<00:00,  1.92it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with 165\n",
            "\n",
            "Predicting 166:\n",
            "perform_everything_on_device: True\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with 166\n",
            "\n",
            "Predicting 167:\n",
            "perform_everything_on_device: True\n",
            "100% 12/12 [00:06<00:00,  1.87it/s]\n",
            "100% 12/12 [00:06<00:00,  1.87it/s]\n",
            "100% 12/12 [00:06<00:00,  1.87it/s]\n",
            "100% 12/12 [00:06<00:00,  1.87it/s]\n",
            "100% 12/12 [00:06<00:00,  1.87it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with 167\n",
            "\n",
            "Predicting 168:\n",
            "perform_everything_on_device: True\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with 168\n",
            "\n",
            "Predicting 169:\n",
            "perform_everything_on_device: True\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "100% 8/8 [00:04<00:00,  1.92it/s]\n",
            "100% 8/8 [00:04<00:00,  1.92it/s]\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with 169\n",
            "\n",
            "Predicting 171:\n",
            "perform_everything_on_device: True\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with 171\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nnUNetv2_apply_postprocessing -i /content/nnUNet/nnUNet_results/Dataset101/inference -o /content/nnUNet/nnUNet_results/Dataset101/postprocessing -pp_pkl_file /content/nnUNet/nnUNet_results/Dataset101/nnUNetTrainer_10epochs__nnUNetPlans__3d_fullres/crossval_results_folds_0_1_2_3_4/postprocessing.pkl -np 8 -plans_json /content/nnUNet/nnUNet_results/Dataset101/nnUNetTrainer_10epochs__nnUNetPlans__3d_fullres/crossval_results_folds_0_1_2_3_4/plans.json"
      ],
      "metadata": {
        "id": "XNSGsmE_aD0K"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}